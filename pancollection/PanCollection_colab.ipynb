{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start for PanCollection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step1. Install package `pancollection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jyxxv0SUtK-C",
    "outputId": "3a6cdf39-a78a-4444-8a89-9a330c02b96a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: udl-vis in d:\\python\\gitsync\\udl-vis (0.2a0)\n",
      "Requirement already satisfied: psutil in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from udl-vis) (5.9.1)\n",
      "Requirement already satisfied: opencv-python in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from udl-vis) (4.5.2.54)\n",
      "Requirement already satisfied: numpy in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from udl-vis) (1.18.5)\n",
      "Requirement already satisfied: matplotlib in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from udl-vis) (3.5.3)\n",
      "Requirement already satisfied: tensorboard in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from udl-vis) (1.15.0)\n",
      "Requirement already satisfied: addict in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages\\addict-2.4.0-py3.7.egg (from udl-vis) (2.4.0)\n",
      "Requirement already satisfied: yapf in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages\\yapf-0.32.0-py3.7.egg (from udl-vis) (0.32.0)\n",
      "Requirement already satisfied: imageio in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from udl-vis) (2.9.0)\n",
      "Requirement already satisfied: colorlog in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from udl-vis) (6.5.0)\n",
      "Requirement already satisfied: scipy in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from udl-vis) (1.6.3)\n",
      "Requirement already satisfied: h5py in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from udl-vis) (2.10.0)\n",
      "Requirement already satisfied: regex in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from udl-vis) (2022.1.18)\n",
      "Requirement already satisfied: packaging in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from udl-vis) (23.0)\n",
      "Requirement already satisfied: pyyaml in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from udl-vis) (5.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\msi\\appdata\\roaming\\python\\python37\\site-packages (from colorlog->udl-vis) (0.4.5)\n",
      "Requirement already satisfied: six in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from h5py->udl-vis) (1.16.0)\n",
      "Requirement already satisfied: pillow in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from imageio->udl-vis) (8.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from matplotlib->udl-vis) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from matplotlib->udl-vis) (2.4.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from matplotlib->udl-vis) (4.38.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from matplotlib->udl-vis) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from matplotlib->udl-vis) (0.10.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from tensorboard->udl-vis) (65.4.0)\n",
      "Requirement already satisfied: grpcio>=1.6.3 in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from tensorboard->udl-vis) (1.38.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from tensorboard->udl-vis) (2.0.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from tensorboard->udl-vis) (0.13.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from tensorboard->udl-vis) (3.3.4)\n",
      "Requirement already satisfied: wheel>=0.26 in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from tensorboard->udl-vis) (0.37.1)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from tensorboard->udl-vis) (3.17.3)\n",
      "Requirement already satisfied: importlib-metadata in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from markdown>=2.6.8->tensorboard->udl-vis) (4.11.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\msi\\appdata\\roaming\\python\\python37\\site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->udl-vis) (4.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->udl-vis) (3.11.0)\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: pancollection==0.2b0 in d:\\python\\gitsync\\udl_package\\pancollection (0.2b0)\n",
      "Requirement already satisfied: psutil in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from pancollection==0.2b0) (5.9.1)\n",
      "Requirement already satisfied: opencv-python in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from pancollection==0.2b0) (4.5.2.54)\n",
      "Requirement already satisfied: numpy in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from pancollection==0.2b0) (1.18.5)\n",
      "Requirement already satisfied: matplotlib in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from pancollection==0.2b0) (3.5.3)\n",
      "Requirement already satisfied: tensorboard in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from pancollection==0.2b0) (1.15.0)\n",
      "Requirement already satisfied: addict in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages\\addict-2.4.0-py3.7.egg (from pancollection==0.2b0) (2.4.0)\n",
      "Requirement already satisfied: yapf in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages\\yapf-0.32.0-py3.7.egg (from pancollection==0.2b0) (0.32.0)\n",
      "Requirement already satisfied: imageio in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from pancollection==0.2b0) (2.9.0)\n",
      "Requirement already satisfied: colorlog in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from pancollection==0.2b0) (6.5.0)\n",
      "Requirement already satisfied: scipy in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from pancollection==0.2b0) (1.6.3)\n",
      "Requirement already satisfied: h5py in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from pancollection==0.2b0) (2.10.0)\n",
      "Requirement already satisfied: regex in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from pancollection==0.2b0) (2022.1.18)\n",
      "Requirement already satisfied: packaging in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from pancollection==0.2b0) (23.0)\n",
      "Requirement already satisfied: pyyaml in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from pancollection==0.2b0) (5.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\msi\\appdata\\roaming\\python\\python37\\site-packages (from colorlog->pancollection==0.2b0) (0.4.5)\n",
      "Requirement already satisfied: six in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from h5py->pancollection==0.2b0) (1.16.0)\n",
      "Requirement already satisfied: pillow in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from imageio->pancollection==0.2b0) (8.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from matplotlib->pancollection==0.2b0) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from matplotlib->pancollection==0.2b0) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from matplotlib->pancollection==0.2b0) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from matplotlib->pancollection==0.2b0) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from matplotlib->pancollection==0.2b0) (1.3.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from tensorboard->pancollection==0.2b0) (0.13.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from tensorboard->pancollection==0.2b0) (65.4.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from tensorboard->pancollection==0.2b0) (2.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from tensorboard->pancollection==0.2b0) (3.3.4)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from tensorboard->pancollection==0.2b0) (3.17.3)\n",
      "Requirement already satisfied: grpcio>=1.6.3 in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from tensorboard->pancollection==0.2b0) (1.38.1)\n",
      "Requirement already satisfied: wheel>=0.26 in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from tensorboard->pancollection==0.2b0) (0.37.1)\n",
      "Requirement already satisfied: importlib-metadata in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from markdown>=2.6.8->tensorboard->pancollection==0.2b0) (4.11.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\msi\\appdata\\roaming\\python\\python37\\site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->pancollection==0.2b0) (4.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\python\\anaconda3\\envs\\latest\\lib\\site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->pancollection==0.2b0) (3.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pancollection --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show udl_vis\n",
    "!pip show pancollection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xdY13-yVu7zi"
   },
   "source": [
    "### Step2. Detect GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3b1zkHAYv2vO",
    "outputId": "79c299f6-01c6-4322-c19c-91b52fd57359"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun  9 18:59:29 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 512.36       Driver Version: 512.36       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   61C    P8     6W /  N/A |      0MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3. Test codes in pretrained chekpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from pancollection.configs.configs import TaskDispatcher\n",
    "import os\n",
    "\n",
    "class parser_args(TaskDispatcher, name='FusionNet'):\n",
    "    def __init__(self, cfg=None, **kwargs):\n",
    "        super(parser_args, self).__init__()\n",
    "\n",
    "        if cfg is None:\n",
    "            from pancollection.configs.configs import panshaprening_cfg\n",
    "            cfg = panshaprening_cfg()\n",
    "\n",
    "        \n",
    "        script_path = os.path.dirname(os.getcwd())\n",
    "        root_dir = script_path.split(cfg.task)[0]\n",
    "\n",
    "        model_path = f'.pth.tar'\n",
    "        dataset_name = kwargs[\"dataset_name\"] if 'dataset_name' in kwargs else \"wv3\"\n",
    "        use_resume = kwargs[\"use_resume\"] if 'use_resume' in kwargs else True\n",
    "\n",
    "        parser = argparse.ArgumentParser(description='PyTorch Pansharpening Training')\n",
    "        # * Logger\n",
    "        parser.add_argument('--out_dir', metavar='DIR', default=f'{root_dir}/results/{cfg.task}',\n",
    "                            help='path to save model')\n",
    "        parser.add_argument('--mode', default=argparse.SUPPRESS, help='protective declare, please ignore it')\n",
    "\n",
    "        parser.add_argument('--lr', default=2e-4, type=float)  # 1e-4 2e-4 8\n",
    "        # parser.add_argument('--lr_scheduler', default=True, type=bool)\n",
    "        parser.add_argument('--samples_per_gpu', default=32, type=int,  # 8\n",
    "                            metavar='N', help='mini-batch size (default: 256)')\n",
    "        parser.add_argument('--print-freq', '-p', default=50, type=int,\n",
    "                            metavar='N', help='print frequency (default: 10)')\n",
    "        parser.add_argument('--seed', default=1, type=int,\n",
    "                            help='seed for initializing training. ')\n",
    "        parser.add_argument('--epochs', default=400, type=int)\n",
    "        parser.add_argument('--workers_per_gpu', default=0, type=int)\n",
    "        parser.add_argument('--resume_from',\n",
    "                            default=model_path,\n",
    "                            type=str, metavar='PATH',\n",
    "                            help='path to latest checkpoint (default: none)')\n",
    "        ##\n",
    "        parser.add_argument('--arch', '-a', metavar='ARCH', default='FusionNet', type=str,\n",
    "                            choices=['PanNet', 'DiCNN', 'PNN', 'FusionNet'])\n",
    "        parser.add_argument('--dataset', default={'train': 'wv3', 'test': 'test_wv3_multiExm1.h5'}, type=str, # 'valid': 'wv3' , 'eval': 'wv3_multiExm.h5'\n",
    "                            choices=[None, 'wv2', 'wv3', 'wv4', 'qb', 'gf2', 'wv3_OrigScale_multiExm1.h5', 'test_wv3_multiExm1.h5'],\n",
    "                            help=\"performing evalution for patch2entire\")\n",
    "        parser.add_argument('--eval', default=False, type=bool,\n",
    "                            help=\"performing evaluation out of training process, which can avoid dead loop !!\")\n",
    "\n",
    "\n",
    "        args = parser.parse_args(args=[])\n",
    "        args.start_epoch = args.best_epoch = 1\n",
    "        args.experimental_desc = 'Test'\n",
    "        cfg.merge_args2cfg(args)\n",
    "        cfg.save_fmt = \"mat\"\n",
    "        # cfg.workflow = [('train', 10), ('val', 1)]\n",
    "        cfg.workflow = [('train', 1)]\n",
    "        # cfg.config = f\"{script_path}/configs/hook_configs.py\"\n",
    "        cfg.use_tfb = False\n",
    "        cfg.img_range = 2047.0 if dataset_name != \"gf2\" else 1023.0\n",
    "        cfg.dataloader_name = \"PanCollection_dataloader\"  # PanCollection_dataloader, oldPan_dataloader, DLPan_dataloader\n",
    "        cfg.merge_args2cfg(args)\n",
    "        \n",
    "        cfg.merge_from_dict(kwargs)  # dict is merged partially\n",
    "        cfg.dataset = kwargs['dataset'] if 'dataset' in kwargs else cfg.dataset\n",
    "        print(cfg.pretty_text)\n",
    "\n",
    "\n",
    "        self.merge_from_dict(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "otIv3bi2uDFa",
    "outputId": "1e95ac5a-e918-4638-f7d4-3fb1c6488685"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\gitsync\\udl_package\\pancollection\\pancollection\\configs\\configs.py:33: UserWarning: Note: FusionNet, DiCNN, PNN don't have high-pass filter\n",
      "  warnings.warn(warning)\n",
      "\u001b[37m- Set random seed to 1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 entrypoint\n",
      "111 None\n",
      "222 pansharpening\n",
      "111 None\n",
      "333 FusionNet\n",
      "accumulated_step = 1\n",
      "amp = None\n",
      "amp_opt_level = 'O0'\n",
      "arch = 'FusionNet'\n",
      "backend = 'nccl'\n",
      "clip_max_norm = 0\n",
      "crop_batch_size = 128\n",
      "device = 'cuda'\n",
      "dist_url = 'env://'\n",
      "global_rank = 0\n",
      "gpu_ids = [0]\n",
      "launcher = 'none'\n",
      "load_model_strict = True\n",
      "local_rank = 0\n",
      "log_dir = 'logs'\n",
      "mode = None\n",
      "model_style = None\n",
      "once_epoch = False\n",
      "reg = True\n",
      "reset_lr = False\n",
      "resume_mode = 'best'\n",
      "rgb_range = 255\n",
      "save_top_k = 5\n",
      "seed = 1\n",
      "start_epoch = 1\n",
      "task = 'pansharpening'\n",
      "tfb_dir = None\n",
      "use_log = True\n",
      "use_tfb = False\n",
      "validate = False\n",
      "scale = [1]\n",
      "data_dir = 'D:/Datasets/pansharpening'\n",
      "best_prec1 = 10000\n",
      "best_prec5 = 10000\n",
      "metrics = 'loss'\n",
      "save_fmt = 'mat'\n",
      "taskhead = 'pansharpening'\n",
      "best_epoch = 1\n",
      "dataset = dict(train='wv3', test='test_wv3_multiExm1.h5')\n",
      "epochs = 400\n",
      "eval = False\n",
      "experimental_desc = 'Test'\n",
      "lr = 0.0003\n",
      "out_dir = 'd:/Python/gitSync/AEM/results/pansharpening'\n",
      "print_freq = 50\n",
      "resume_from = '.pth.tar'\n",
      "samples_per_gpu = 32\n",
      "workers_per_gpu = 0\n",
      "workflow = [('train', 1)]\n",
      "dataloader_name = 'PanCollection_dataloader'\n",
      "img_range = 1023.0\n",
      "dataset_name = 'gf2'\n",
      "use_resume = False\n",
      "\n",
      "{'entrypoint': <class 'udl_vis.Basis.option.get_cfg'>, 'pansharpening': <class 'pancollection.configs.configs.panshaprening_cfg'>, 'BDPN': <class 'pancollection.configs.option_bdpn.parser_args'>, 'DCFNet': <class 'pancollection.configs.option_DCFNet.parser_args'>, 'DiCNN': <class 'pancollection.configs.option_dicnn.parser_args'>, 'DRPNN': <class 'pancollection.configs.option_drpnn.parser_args'>, 'FusionNet': <class 'pancollection.configs.option_fusionnet.parser_args'>, 'LAGNet': <class 'pancollection.configs.option_LAGNet.parser_args'>, 'MSDCNN': <class 'pancollection.configs.option_msdcnn.parser_args'>, 'PanNet': <class 'pancollection.configs.option_pannet.parser_args'>, 'PNN': <class 'pancollection.configs.option_pnn.parser_args'>}\n",
      "=> creating d:\\Python\\gitSync\\AEM\\results\\pansharpening\\wv3\\FusionNet\\Test\n",
      "=> creating tfb logs d:\\Python\\gitSync\\AEM\\results\\pansharpening\\logs\\wv3\\FusionNet\\Test_2023-06-10-01-34-03\n",
      "loading Dataset_Pro: D:/Datasets/pansharpening/PanCollection/training_data/train_wv3_9714.h5 with 1023.0, keys: <KeysViewHDF5 ['gt', 'lms', 'ms', 'pan']>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Anaconda3\\envs\\latest\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "d:\\python\\gitsync\\udl-vis\\udl_vis\\AutoDL\\trainer.py:120: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.\n",
      "  'please set `runner` in your config.', UserWarning)\n",
      "d:\\python\\gitsync\\udl_package\\pancollection\\pancollection\\common\\dataset.py:21: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  data = h5py.File(file_path)  # NxCxHxW = 0x1x2x3\n",
      "d:\\python\\gitsync\\udl-vis\\udl_vis\\mmcv\\runner\\checkpoint.py:585: UserWarning: checkpoint in directory d:\\Python\\gitSync\\AEM\\results\\pansharpening\\wv3\\FusionNet\\Test\\model_2023-06-10-01-34-03\\checkpoint don't exist or is empty\n",
      "  warnings.warn(msg)\n",
      "\u001b[37m- loading best model failed, maybe it's from scratch currently.\u001b[0m\n",
      "\u001b[37m- no checkpoint found at .pth.tar\u001b[0m\n",
      "\u001b[37m- resumed epoch 1, iter 1\u001b[0m\n",
      "\u001b[37m- Start running, host: msi@LAPTOP-JTEEC3T0, work_dir: d:\\Python\\gitSync\\AEM\\results\\pansharpening\\wv3\\FusionNet\\Test\\model_2023-06-10-01-34-03\u001b[0m\n",
      "\u001b[37m- Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(NORMAL      ) ModelCheckpoint                    \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) ModelCheckpoint                    \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) ModelCheckpoint                    \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \u001b[0m\n",
      "\u001b[37m- workflow: [('train', 1)], max: 400 epochs\u001b[0m\n",
      "\u001b[37m- Checkpoints will be saved to d:\\Python\\gitSync\\AEM\\results\\pansharpening\\wv3\\FusionNet\\Test\\model_2023-06-10-01-34-03\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9714, 1, 64, 64) (9714, 8, 64, 64) (9714, 8, 64, 64) (9714, 8, 16, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m- Epoch [1]/[400][50/303]\tlr: 3.000e-04, eta: 3:32:15, time: 0.105, data_time: 0.046, memory: 203MB, pan2ms: 0.00780, loss: 0.00780, grad_norm: 0.02161\u001b[0m\n",
      "\u001b[37m- Epoch [1]/[400][100/303]\tlr: 3.000e-04, eta: 3:03:56, time: 0.077, data_time: 0.026, memory: 203MB, pan2ms: 0.00608, loss: 0.00608, grad_norm: 0.01404\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12620\\3949891319.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m                              dataset={'train': 'wv3', 'test': 'test_wv3_multiExm1.h5'})\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTaskDispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_task\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mpan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetDataSession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\python\\gitsync\\udl-vis\\udl_vis\\AutoDL\\trainer.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(cfg, build_model, getDataSession)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[0mgetDataSession\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[0mdistributed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m         meta={})\n\u001b[0m",
      "\u001b[1;32md:\\python\\gitsync\\udl-vis\\udl_vis\\AutoDL\\trainer.py\u001b[0m in \u001b[0;36mtrainer\u001b[1;34m(cfg, logger, build_model, getDataSession, distributed, meta)\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;31m# 载入数据，运行模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[1;31m############################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m     \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkflow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\gitsync\\udl-vis\\udl_vis\\mmcv\\runner\\epoch_based_runner.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, data_loaders, workflow, max_epochs, **kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'train'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_epochs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m                     \u001b[0mepoch_runner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mearlyStop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m                 \u001b[0mprint_log\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model train has diverged, python will stop training\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\gitsync\\udl-vis\\udl_vis\\mmcv\\runner\\epoch_based_runner.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, data_loader, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'before_train_iter'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'after_train_iter'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\gitsync\\udl-vis\\udl_vis\\mmcv\\runner\\epoch_based_runner.py\u001b[0m in \u001b[0;36mrun_iter\u001b[1;34m(self, data_batch, train_mode, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtrain_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             outputs = self.model.train_step(data_batch, self.optimizer,\n\u001b[1;32m---> 32\u001b[1;33m                                         **kwargs)\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;31m# if not isinstance(self.model, dict):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\gitsync\\udl_package\\pancollection\\pancollection\\models\\base_model.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0mloss_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\gitsync\\udl-vis\\udl_vis\\mmcv\\parallel\\data_parallel.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mval_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\gitsync\\udl_package\\pancollection\\pancollection\\models\\FusionNet\\model_fusionnet.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mgt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'gt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lms'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                            \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ms'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pan'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m         \u001b[0msr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlms\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mres\u001b[0m  \u001b[1;31m# output:= lms + hp_sr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\Anaconda3\\envs\\latest\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\gitsync\\udl_package\\pancollection\\pancollection\\models\\FusionNet\\model_fusionnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[0mrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Bsx32x64x64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[0mrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# ResNet's backbone!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Bsx8x64x64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\Anaconda3\\envs\\latest\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\Anaconda3\\envs\\latest\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\Anaconda3\\envs\\latest\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\gitsync\\udl_package\\pancollection\\pancollection\\models\\FusionNet\\model_fusionnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# x= hp of ms; y = hp of pan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mrs1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv20\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Bsx32x64x64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[0mrs1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv21\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrs1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Bsx32x64x64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrs1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Bsx32x64x64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\Anaconda3\\envs\\latest\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\Anaconda3\\envs\\latest\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\Anaconda3\\envs\\latest\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    459\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[1;32m--> 460\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "# %autoreload 2\n",
    "%aimport udl_vis\n",
    "%aimport pancollection\n",
    "\n",
    "\n",
    "import pancollection as pan\n",
    "cfg = pan.TaskDispatcher.new(task='pansharpening', mode='entrypoint', arch='FusionNet', \n",
    "                             dataset_name=\"gf2\", use_resume=True, eval=True,\n",
    "                             dataset={'train': 'wv3', 'test': 'test_wv3_multiExm1.h5'})\n",
    "print(pan.TaskDispatcher._task)\n",
    "pan.trainer.main(cfg, pan.build_model, pan.getDataSession)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\gitsync\\udl_package\\pancollection\\pancollection\\configs\\configs.py:33: UserWarning: Note: FusionNet, DiCNN, PNN don't have high-pass filter\n",
      "  warnings.warn(warning)\n",
      "\u001b[37m- Set random seed to 1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 entrypoint\n",
      "111 None\n",
      "222 pansharpening\n",
      "111 None\n",
      "333 PNN\n",
      "accumulated_step = 1\n",
      "amp = None\n",
      "amp_opt_level = 'O0'\n",
      "arch = 'PNN'\n",
      "backend = 'nccl'\n",
      "clip_max_norm = 0\n",
      "crop_batch_size = 128\n",
      "device = 'cuda'\n",
      "dist_url = 'env://'\n",
      "global_rank = 0\n",
      "gpu_ids = [0]\n",
      "launcher = 'none'\n",
      "load_model_strict = True\n",
      "local_rank = 0\n",
      "log_dir = 'logs'\n",
      "mode = None\n",
      "model_style = None\n",
      "once_epoch = False\n",
      "reg = True\n",
      "reset_lr = False\n",
      "resume_mode = 'best'\n",
      "rgb_range = 255\n",
      "save_top_k = 5\n",
      "seed = 1\n",
      "start_epoch = 1\n",
      "task = 'pansharpening'\n",
      "tfb_dir = None\n",
      "use_log = True\n",
      "use_tfb = False\n",
      "validate = False\n",
      "scale = [1]\n",
      "data_dir = 'D:/Datasets/pansharpening'\n",
      "best_prec1 = 10000\n",
      "best_prec5 = 10000\n",
      "metrics = 'loss'\n",
      "save_fmt = 'mat'\n",
      "taskhead = 'pansharpening'\n",
      "best_epoch = 1\n",
      "dataset = dict(test='test_gf2_multiExm1.h5')\n",
      "epochs = 12000\n",
      "eval = True\n",
      "experimental_desc = 'Test'\n",
      "lr = 0.001\n",
      "lr_scheduler = True\n",
      "out_dir = 'd:/Python/gitSync/AEM/results/pansharpening'\n",
      "print_freq = 500\n",
      "resume_from = 'D:/Python/gitSync/ckpts/PanCollection/gf2/PNN/11998.pth.tar'\n",
      "samples_per_gpu = 64\n",
      "workers_per_gpu = 0\n",
      "workflow = [('train', 1)]\n",
      "img_range = 1023.0\n",
      "dataloader_name = 'PanCollection_dataloader'\n",
      "dataset_name = 'gf2'\n",
      "\n",
      "dict_keys(['entrypoint', 'pansharpening', 'BDPN', 'DCFNet', 'DiCNN', 'DRPNN', 'FusionNet', 'LAGNet', 'MSDCNN', 'PanNet', 'PNN'])\n",
      "=> creating d:\\Python\\gitSync\\AEM\\results\\pansharpening\\test_gf2_multiExm1.h5\\PNN\\Test\n",
      "PNN adopted another lr: 0.11560000000000001 in \"build_pnn in pnn_main.py\" \n",
      "loading MultiExmTest_h5: D:/Datasets/pansharpening/PanCollection/test_data/test_gf2_multiExm1.h5 with 1023.0\n",
      "<KeysViewHDF5 ['gt', 'lms', 'ms', 'pan']>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Anaconda3\\envs\\latest\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "d:\\python\\gitsync\\udl-vis\\udl_vis\\AutoDL\\trainer.py:120: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.\n",
      "  'please set `runner` in your config.', UserWarning)\n",
      "d:\\python\\gitsync\\udl_package\\pancollection\\pancollection\\common\\dataset.py:144: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  data = h5py.File(file_path)  # CxHxW\n",
      "d:\\python\\gitsync\\udl-vis\\udl_vis\\mmcv\\runner\\checkpoint.py:585: UserWarning: checkpoint in directory d:\\Python\\gitSync\\AEM\\results\\pansharpening\\test_gf2_multiExm1.h5\\PNN\\Test\\PNN\\checkpoint don't exist or is empty\n",
      "  warnings.warn(msg)\n",
      "\u001b[37m- loading best model failed, maybe it's from scratch currently.\u001b[0m\n",
      "\u001b[37m- load checkpoint from local path: D:/Python/gitSync/ckpts/PanCollection/gf2/PNN\\11998.pth.tar\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lms: torch.Size([20, 4, 256, 256]), ms: torch.Size([20, 4, 64, 64]), pan: torch.Size([20, 1, 256, 256]), gt: torch.Size([20, 256, 256, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m- resumed epoch 11998, iter 3707383\u001b[0m\n",
      "\u001b[37m- Start running, host: msi@LAPTOP-JTEEC3T0, work_dir: d:\\Python\\gitSync\\AEM\\results\\pansharpening\\test_gf2_multiExm1.h5\\PNN\\Test\\PNN\u001b[0m\n",
      "\u001b[37m- Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(NORMAL      ) ModelCheckpoint                    \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) ModelCheckpoint                    \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) ModelCheckpoint                    \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \u001b[0m\n",
      "\u001b[37m- workflow: [('val', 1)], max: 11998 epochs\u001b[0m\n",
      "\u001b[37m- Checkpoints will be saved to d:\\Python\\gitSync\\AEM\\results\\pansharpening\\test_gf2_multiExm1.h5\\PNN\\Test\\PNN\u001b[0m\n",
      "\u001b[37m- Epoch(val) [11998][1]\tSAM: 1.04891, ERGAS: 1.20399, PSNR: 36.41916\u001b[0m\n",
      "\u001b[37m- Epoch(val) [11998][2]\tSAM: 0.98809, ERGAS: 1.11819, PSNR: 37.48595\u001b[0m\n",
      "\u001b[37m- Epoch(val) [11998][3]\tSAM: 0.88283, ERGAS: 1.01267, PSNR: 39.27004\u001b[0m\n",
      "\u001b[37m- Epoch(val) [11998][4]\tSAM: 0.90418, ERGAS: 1.01648, PSNR: 39.35704\u001b[0m\n",
      "\u001b[37m- Epoch(val) [11998][5]\tSAM: 0.92199, ERGAS: 1.02116, PSNR: 39.29014\u001b[0m\n",
      "\u001b[37m- Epoch(val) [11998][6]\tSAM: 0.98336, ERGAS: 1.04122, PSNR: 39.27524\u001b[0m\n",
      "\u001b[37m- Epoch(val) [11998][7]\tSAM: 0.99467, ERGAS: 1.05162, PSNR: 39.15391\u001b[0m\n",
      "\u001b[37m- Epoch(val) [11998][8]\tSAM: 0.98143, ERGAS: 1.03970, PSNR: 39.13124\u001b[0m\n",
      "\u001b[37m- Epoch(val) [11998][9]\tSAM: 1.02256, ERGAS: 1.07293, PSNR: 38.83985\u001b[0m\n",
      "\u001b[37m- Epoch(val) [11998][10]\tSAM: 1.04057, ERGAS: 1.10108, PSNR: 38.61836\u001b[0m\n",
      "\u001b[37m- Epoch(val) [11998][11]\tSAM: 1.06569, ERGAS: 1.12708, PSNR: 38.48678\u001b[0m\n",
      "\u001b[37m- Epoch(val) [11998][12]\tSAM: 1.07991, ERGAS: 1.13944, PSNR: 38.37525\u001b[0m\n",
      "\u001b[37m- Epoch(val) [11998][13]\tSAM: 1.09021, ERGAS: 1.15249, PSNR: 38.29384\u001b[0m\n",
      "\u001b[37m- Epoch(val) [11998][14]\tSAM: 1.09459, ERGAS: 1.15326, PSNR: 38.30527\u001b[0m\n",
      "\u001b[37m- Epoch(val) [11998][15]\tSAM: 1.10602, ERGAS: 1.15750, PSNR: 38.23186\u001b[0m\n",
      "\u001b[37m- Epoch(val) [11998][16]\tSAM: 1.11858, ERGAS: 1.17602, PSNR: 38.12878\u001b[0m\n",
      "\u001b[37m- Epoch(val) [11998][17]\tSAM: 1.12158, ERGAS: 1.18070, PSNR: 38.14068\u001b[0m\n",
      "\u001b[37m- Epoch(val) [11998][18]\tSAM: 1.11815, ERGAS: 1.17894, PSNR: 38.06916\u001b[0m\n",
      "\u001b[37m- Epoch(val) [11998][19]\tSAM: 1.14399, ERGAS: 1.19797, PSNR: 37.92580\u001b[0m\n",
      "\u001b[37m- Epoch(val) [11998][20]\tSAM: 1.14250, ERGAS: 1.19164, PSNR: 37.96740\u001b[0m\n",
      "\u001b[37m- Epoch(val) [11998][20]\tSAM: 1.14250, ERGAS: 1.19164, PSNR: 37.96740\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test time: 10.62796401977539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m- Training time 0:00:13\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pancollection.run_test_pansharpening import run_test\n",
    "arch='PNN'\n",
    "# dataset_name='gf2'\n",
    "# cfg = dict(arch=arch, dataset_name=dataset_name, eval=True,\n",
    "            #  dataset={'test': f'test_{dataset_name}_multiExm1_hp.h5'} if arch == \"PanNet\" else {'test': f'test_{dataset_name}_multiExm1.h5'}))\n",
    "cfg = dict(arch=arch, eval=True)\n",
    "run_test(**cfg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step4. Training codes in GaoFen-2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "# %autoreload 2\n",
    "%aimport udl_vis\n",
    "%aimport pancollection\n",
    "\n",
    "\n",
    "import pancollection as pan\n",
    "cfg = pan.TaskDispatcher.new(task='pansharpening', mode='entrypoint', arch='FusionNet', \n",
    "                             dataset_name=\"gf2\", use_resume=False,\n",
    "                             dataset={'train': 'gf2', 'test': 'test_gf2_multiExm1.h5'})\n",
    "print(pan.TaskDispatcher._task)\n",
    "pan.trainer.main(cfg, pan.build_model, pan.getDataSession)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\gitsync\\udl_package\\pancollection\\pancollection\\configs\\configs.py:33: UserWarning: Note: FusionNet, DiCNN, PNN don't have high-pass filter\n",
      "  warnings.warn(warning)\n",
      "\u001b[37m- Set random seed to 1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 entrypoint\n",
      "111 None\n",
      "222 pansharpening\n",
      "111 None\n",
      "333 PNN\n",
      "accumulated_step = 1\n",
      "amp = None\n",
      "amp_opt_level = 'O0'\n",
      "arch = 'PNN'\n",
      "backend = 'nccl'\n",
      "clip_max_norm = 0\n",
      "crop_batch_size = 128\n",
      "device = 'cuda'\n",
      "dist_url = 'env://'\n",
      "global_rank = 0\n",
      "gpu_ids = [0]\n",
      "launcher = 'none'\n",
      "load_model_strict = True\n",
      "local_rank = 0\n",
      "log_dir = 'logs'\n",
      "mode = None\n",
      "model_style = None\n",
      "once_epoch = False\n",
      "reg = True\n",
      "reset_lr = False\n",
      "resume_mode = 'best'\n",
      "rgb_range = 255\n",
      "save_top_k = 5\n",
      "seed = 1\n",
      "start_epoch = 1\n",
      "task = 'pansharpening'\n",
      "tfb_dir = None\n",
      "use_log = True\n",
      "use_tfb = False\n",
      "validate = False\n",
      "scale = [1]\n",
      "data_dir = 'D:/Datasets/pansharpening'\n",
      "best_prec1 = 10000\n",
      "best_prec5 = 10000\n",
      "metrics = 'loss'\n",
      "save_fmt = 'mat'\n",
      "taskhead = 'pansharpening'\n",
      "best_epoch = 1\n",
      "dataset = dict(train='wv3', test='wv3_multiExm1.h5')\n",
      "epochs = 12000\n",
      "eval = False\n",
      "experimental_desc = 'Test'\n",
      "lr = 0.001\n",
      "lr_scheduler = True\n",
      "out_dir = 'd:/Python/gitSync/AEM/results/pansharpening'\n",
      "print_freq = 500\n",
      "resume_from = 'D:/Python/gitSync/ckpts/PanCollection/gf2/PNN/11998.pth.tar'\n",
      "samples_per_gpu = 64\n",
      "workers_per_gpu = 0\n",
      "workflow = [('train', 1)]\n",
      "img_range = 1023.0\n",
      "dataloader_name = 'PanCollection_dataloader'\n",
      "dataset_name = 'gf2'\n",
      "\n",
      "dict_keys(['entrypoint', 'pansharpening', 'BDPN', 'DCFNet', 'DiCNN', 'DRPNN', 'FusionNet', 'LAGNet', 'MSDCNN', 'PanNet', 'PNN'])\n",
      "=> creating d:\\Python\\gitSync\\AEM\\results\\pansharpening\\wv3\\PNN\\Test\n",
      "=> creating tfb logs d:\\Python\\gitSync\\AEM\\results\\pansharpening\\logs\\wv3\\PNN\\Test_2023-06-10-02-16-46\n",
      "PNN adopted another lr: 0.23120000000000002 in \"build_pnn in pnn_main.py\" \n",
      "loading Dataset_Pro: D:/Datasets/pansharpening/PanCollection/training_data/train_wv3_9714.h5 with 1023.0, keys: <KeysViewHDF5 ['gt', 'lms', 'ms', 'pan']>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Anaconda3\\envs\\latest\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "d:\\python\\gitsync\\udl-vis\\udl_vis\\AutoDL\\trainer.py:120: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.\n",
      "  'please set `runner` in your config.', UserWarning)\n",
      "d:\\python\\gitsync\\udl_package\\pancollection\\pancollection\\common\\dataset.py:21: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  data = h5py.File(file_path)  # NxCxHxW = 0x1x2x3\n",
      "d:\\python\\gitsync\\udl-vis\\udl_vis\\mmcv\\runner\\checkpoint.py:585: UserWarning: checkpoint in directory d:\\Python\\gitSync\\AEM\\results\\pansharpening\\wv3\\PNN\\Test\\model_2023-06-10-02-16-46\\checkpoint don't exist or is empty\n",
      "  warnings.warn(msg)\n",
      "\u001b[37m- loading best model failed, maybe it's from scratch currently.\u001b[0m\n",
      "\u001b[37m- load checkpoint from local path: D:/Python/gitSync/ckpts/PanCollection/gf2/PNN\\11998.pth.tar\u001b[0m\n",
      "\u001b[33m- The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for conv1.weight: copying a param with shape torch.Size([64, 5, 9, 9]) from checkpoint, the shape in current model is torch.Size([64, 9, 9, 9]).\n",
      "size mismatch for conv3.weight: copying a param with shape torch.Size([4, 32, 5, 5]) from checkpoint, the shape in current model is torch.Size([8, 32, 5, 5]).\n",
      "size mismatch for conv3.bias: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([8]).\u001b[0m\n",
      "\u001b[37m- resumed epoch 11998, iter 3707383\u001b[0m\n",
      "\u001b[37m- Start running, host: msi@LAPTOP-JTEEC3T0, work_dir: d:\\Python\\gitSync\\AEM\\results\\pansharpening\\wv3\\PNN\\Test\\model_2023-06-10-02-16-46\u001b[0m\n",
      "\u001b[37m- Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(NORMAL      ) ModelCheckpoint                    \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) ModelCheckpoint                    \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) ModelCheckpoint                    \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \u001b[0m\n",
      "\u001b[37m- workflow: [('train', 1)], max: 12000 epochs\u001b[0m\n",
      "\u001b[37m- Checkpoints will be saved to d:\\Python\\gitSync\\AEM\\results\\pansharpening\\wv3\\PNN\\Test\\model_2023-06-10-02-16-46\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9714, 1, 64, 64) (9714, 8, 64, 64) (9714, 8, 64, 64) (9714, 8, 16, 16)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (5) must match the size of tensor b (9) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10612\\1374230135.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#              dataset={'train': 'gf2', 'test': 'test_gf2_multiExm1.h5'})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mcfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0march\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0march\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mrun_demo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\python\\gitsync\\udl_package\\pancollection\\pancollection\\run_pansharpening.py\u001b[0m in \u001b[0;36mrun_demo\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     13\u001b[0m                              )\n\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTaskDispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_task\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetDataSession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;31m# or\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# import pancollection as pan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\gitsync\\udl-vis\\udl_vis\\AutoDL\\trainer.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(cfg, build_model, getDataSession)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[0mgetDataSession\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[0mdistributed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m         meta={})\n\u001b[0m",
      "\u001b[1;32md:\\python\\gitsync\\udl-vis\\udl_vis\\AutoDL\\trainer.py\u001b[0m in \u001b[0;36mtrainer\u001b[1;34m(cfg, logger, build_model, getDataSession, distributed, meta)\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;31m# 载入数据，运行模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[1;31m############################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m     \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkflow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\gitsync\\udl-vis\\udl_vis\\mmcv\\runner\\epoch_based_runner.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, data_loaders, workflow, max_epochs, **kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'train'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_epochs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m                     \u001b[0mepoch_runner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mearlyStop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m                 \u001b[0mprint_log\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model train has diverged, python will stop training\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\gitsync\\udl-vis\\udl_vis\\mmcv\\runner\\epoch_based_runner.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, data_loader, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'before_train_iter'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'after_train_iter'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\gitsync\\udl-vis\\udl_vis\\mmcv\\runner\\base_runner.py\u001b[0m in \u001b[0;36mcall_hook\u001b[1;34m(self, fn_name)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \"\"\"\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_hook_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\gitsync\\udl-vis\\udl_vis\\mmcv\\runner\\hooks\\optimizer.py\u001b[0m in \u001b[0;36mafter_train_iter\u001b[1;34m(self, runner)\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'grad_norm'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m             \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdetect_anomalous_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunner\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\Anaconda3\\envs\\latest\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m                     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\Anaconda3\\envs\\latest\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'differentiable'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\Anaconda3\\envs\\latest\\lib\\site-packages\\torch\\optim\\sgd.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    159\u001b[0m                 \u001b[0mmaximize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'maximize'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m                 \u001b[0mhas_sparse_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhas_sparse_grad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m                 foreach=group['foreach'])\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m             \u001b[1;31m# update momentum_buffers in state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\Anaconda3\\envs\\latest\\lib\\site-packages\\torch\\optim\\sgd.py\u001b[0m in \u001b[0;36msgd\u001b[1;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[0;32m    209\u001b[0m          \u001b[0mnesterov\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnesterov\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m          \u001b[0mhas_sparse_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhas_sparse_grad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m          maximize=maximize)\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m def _single_tensor_sgd(params: List[Tensor],\n",
      "\u001b[1;32md:\\Python\\Anaconda3\\envs\\latest\\lib\\site-packages\\torch\\optim\\sgd.py\u001b[0m in \u001b[0;36m_single_tensor_sgd\u001b[1;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[0m\n\u001b[0;32m    236\u001b[0m                 \u001b[0mmomentum_buffer_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m                 \u001b[0mbuf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (9) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "from pancollection.run_pansharpening import run_demo\n",
    "arch='PNN'\n",
    "# dataset_name='gf2'\n",
    "# cfg = dict(arch=arch, dataset_name=dataset_name, use_resume=False,\n",
    "#              dataset={'train': 'gf2', 'test': 'test_gf2_multiExm1.h5'})\n",
    "cfg = dict(arch=arch)\n",
    "run_demo(**cfg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `How to custome the new model and the configs in PanCollection`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from pancollection.models.FusionNet.model_fusionnet import Resblock\n",
    "\n",
    "\n",
    "class myFusionNet(nn.Module):\n",
    "    def __init__(self, spectral_num, criterion, channel=32):\n",
    "        super(myFusionNet, self).__init__()\n",
    "        # ConvTranspose2d: output = (input - 1)*stride + outpading - 2*padding + kernelsize\n",
    "        self.spectral_num = spectral_num\n",
    "        self.criterion = criterion\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=spectral_num, out_channels=channel, kernel_size=3, stride=1, padding=1,\n",
    "                               bias=True)\n",
    "        self.res1 = Resblock()\n",
    "        self.res2 = Resblock()\n",
    "        self.res3 = Resblock()\n",
    "        self.res4 = Resblock()\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=channel, out_channels=spectral_num, kernel_size=3, stride=1, padding=1,\n",
    "                               bias=True)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.backbone = nn.Sequential(  # method 2: 4 resnet repeated blocks\n",
    "            self.res1,\n",
    "            self.res2,\n",
    "            self.res3,\n",
    "            self.res4\n",
    "        )\n",
    "\n",
    "        # init_weights(self.backbone, self.conv1, self.conv3)   # state initialization, important!\n",
    "        # self.apply(init_weights)\n",
    "\n",
    "    def forward(self, x, y):  # x= lms; y = pan\n",
    "\n",
    "        pan_concat = y.repeat(1, self.spectral_num, 1, 1)  # Bsx8x64x64\n",
    "        input = torch.sub(pan_concat, x)  # Bsx8x64x64\n",
    "        rs = self.relu(self.conv1(input))  # Bsx32x64x64\n",
    "\n",
    "        rs = self.backbone(rs)  # ResNet's backbone!\n",
    "        output = self.conv3(rs)  # Bsx8x64x64\n",
    "\n",
    "        return output  # lms + outs\n",
    "\n",
    "    def train_step(self, data, *args, **kwargs):\n",
    "        log_vars = {}\n",
    "        gt, lms, ms, pan = data['gt'].cuda(), data['lms'].cuda(), \\\n",
    "                           data['ms'].cuda(), data['pan'].cuda()\n",
    "        res = self(lms, pan)\n",
    "        sr = lms + res  # output:= lms + hp_sr\n",
    "        loss = self.criterion(sr, gt, *args, **kwargs)['loss']\n",
    "        # outputs = loss\n",
    "        # return loss\n",
    "        log_vars.update(pan2ms=loss.item(), loss=loss.item())\n",
    "        metrics = {'loss': loss, 'log_vars': log_vars}\n",
    "        return metrics\n",
    "\n",
    "    def val_step(self, data, *args, **kwargs):\n",
    "        # gt, lms, ms, pan = data\n",
    "        gt, lms, ms, pan = data['gt'].cuda(), data['lms'].cuda(), \\\n",
    "                           data['ms'].cuda(), data['pan'].cuda()\n",
    "        res = self(lms, pan)\n",
    "        sr = lms + res  # output:= lms + hp_sr\n",
    "\n",
    "        return sr, gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from udl_vis.Basis.criterion_metrics import SetCriterion\n",
    "from pancollection.models.base_model import PanSharpeningModel\n",
    "\n",
    "class build_fusionnet(PanSharpeningModel, name='myFusionNet'):\n",
    "    def __call__(self, args):\n",
    "        scheduler = None\n",
    "        if any([\"wv\" in v for v in args.dataset.values()]):\n",
    "            spectral_num = 8\n",
    "        else:\n",
    "            spectral_num = 4\n",
    "\n",
    "\n",
    "        loss = nn.MSELoss(size_average=True).cuda()  ## Define the Loss function\n",
    "        weight_dict = {'loss': 1}\n",
    "        losses = {'loss': loss}\n",
    "        criterion = SetCriterion(losses, weight_dict)\n",
    "        model = myFusionNet(spectral_num, criterion).cuda()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=0)   ## optimizer 1: Adam\n",
    "\n",
    "        return model, criterion, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from pancollection.configs.configs import TaskDispatcher\n",
    "import os\n",
    "\n",
    "class parser_args(TaskDispatcher, name='myFusionNet'):\n",
    "    def __init__(self, cfg=None, **kwargs):\n",
    "        super(parser_args, self).__init__()\n",
    "\n",
    "        if cfg is None:\n",
    "            from pancollection.configs.configs import panshaprening_cfg\n",
    "            cfg = panshaprening_cfg()\n",
    "\n",
    "        \n",
    "        script_path = os.path.dirname(os.getcwd())\n",
    "        root_dir = script_path.split(cfg.task)[0]\n",
    "\n",
    "        model_path = f'.pth.tar'\n",
    "        dataset_name = kwargs[\"dataset_name\"] if 'dataset_name' in kwargs else \"wv3\"\n",
    "        use_resume = kwargs[\"use_resume\"] if 'use_resume' in kwargs else True\n",
    "\n",
    "        parser = argparse.ArgumentParser(description='PyTorch Pansharpening Training')\n",
    "        # * Logger\n",
    "        parser.add_argument('--out_dir', metavar='DIR', default=f'{root_dir}/results/{cfg.task}',\n",
    "                            help='path to save model')\n",
    "        parser.add_argument('--mode', default=argparse.SUPPRESS, help='protective declare, please ignore it')\n",
    "\n",
    "        parser.add_argument('--lr', default=2e-4, type=float)  # 1e-4 2e-4 8\n",
    "        # parser.add_argument('--lr_scheduler', default=True, type=bool)\n",
    "        parser.add_argument('--samples_per_gpu', default=32, type=int,  # 8\n",
    "                            metavar='N', help='mini-batch size (default: 256)')\n",
    "        parser.add_argument('--print-freq', '-p', default=50, type=int,\n",
    "                            metavar='N', help='print frequency (default: 10)')\n",
    "        parser.add_argument('--seed', default=1, type=int,\n",
    "                            help='seed for initializing training. ')\n",
    "        parser.add_argument('--epochs', default=400, type=int)\n",
    "        parser.add_argument('--workers_per_gpu', default=0, type=int)\n",
    "        parser.add_argument('--resume_from',\n",
    "                            default=model_path,\n",
    "                            type=str, metavar='PATH',\n",
    "                            help='path to latest checkpoint (default: none)')\n",
    "        ##\n",
    "        parser.add_argument('--arch', '-a', metavar='ARCH', default='FusionNet', type=str,\n",
    "                            choices=['PanNet', 'DiCNN', 'PNN', 'FusionNet'])\n",
    "        parser.add_argument('--dataset', default={'train': 'wv3', 'test': 'test_wv3_multiExm1.h5'}, type=str, # 'valid': 'wv3' , 'eval': 'wv3_multiExm.h5'\n",
    "                            choices=[None, 'wv2', 'wv3', 'wv4', 'qb', 'gf2', 'wv3_OrigScale_multiExm1.h5', 'test_wv3_multiExm1.h5'],\n",
    "                            help=\"performing evalution for patch2entire\")\n",
    "        parser.add_argument('--eval', default=False, type=bool,\n",
    "                            help=\"performing evaluation out of training process, which can avoid dead loop !!\")\n",
    "\n",
    "\n",
    "        args = parser.parse_args(args=[])\n",
    "        args.start_epoch = args.best_epoch = 1\n",
    "        args.experimental_desc = 'Test'\n",
    "        cfg.merge_args2cfg(args)\n",
    "        cfg.save_fmt = \"mat\"\n",
    "        # cfg.workflow = [('train', 10), ('val', 1)]\n",
    "        cfg.workflow = [('train', 1)]\n",
    "        # cfg.config = f\"{script_path}/configs/hook_configs.py\"\n",
    "        cfg.use_tfb = False\n",
    "        cfg.img_range = 2047.0 if dataset_name != \"gf2\" else 1023.0\n",
    "        cfg.dataloader_name = \"PanCollection_dataloader\"  # PanCollection_dataloader, oldPan_dataloader, DLPan_dataloader\n",
    "        cfg.merge_args2cfg(args)\n",
    "        \n",
    "        cfg.merge_from_dict(kwargs)  # dict is merged partially\n",
    "        cfg.dataset = kwargs['dataset'] if 'dataset' in kwargs else cfg.dataset\n",
    "        print(cfg.pretty_text)\n",
    "\n",
    "\n",
    "        self.merge_from_dict(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m- Set random seed to 1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 entrypoint\n",
      "111 None\n",
      "222 pansharpening\n",
      "111 None\n",
      "333 myFusionNet\n",
      "accumulated_step = 1\n",
      "amp = None\n",
      "amp_opt_level = 'O0'\n",
      "arch = 'FusionNet'\n",
      "backend = 'nccl'\n",
      "clip_max_norm = 0\n",
      "crop_batch_size = 128\n",
      "device = 'cuda'\n",
      "dist_url = 'env://'\n",
      "global_rank = 0\n",
      "gpu_ids = [0]\n",
      "launcher = 'none'\n",
      "load_model_strict = True\n",
      "local_rank = 0\n",
      "log_dir = 'logs'\n",
      "mode = None\n",
      "model_style = None\n",
      "once_epoch = False\n",
      "reg = True\n",
      "reset_lr = False\n",
      "resume_mode = 'best'\n",
      "rgb_range = 255\n",
      "save_top_k = 5\n",
      "seed = 1\n",
      "start_epoch = 1\n",
      "task = 'pansharpening'\n",
      "tfb_dir = None\n",
      "use_log = True\n",
      "use_tfb = False\n",
      "validate = False\n",
      "scale = [1]\n",
      "data_dir = 'D:/Datasets/pansharpening'\n",
      "best_prec1 = 10000\n",
      "best_prec5 = 10000\n",
      "metrics = 'loss'\n",
      "save_fmt = 'mat'\n",
      "taskhead = 'pansharpening'\n",
      "best_epoch = 1\n",
      "dataset = dict(train='wv3', test='test_wv3_multiExm1.h5')\n",
      "epochs = 400\n",
      "eval = False\n",
      "experimental_desc = 'Test'\n",
      "lr = 0.0002\n",
      "out_dir = 'd:/Python/gitSync/AEM/results/pansharpening'\n",
      "print_freq = 50\n",
      "resume_from = '.pth.tar'\n",
      "samples_per_gpu = 32\n",
      "workers_per_gpu = 0\n",
      "workflow = [('train', 1)]\n",
      "img_range = 1023.0\n",
      "dataloader_name = 'PanCollection_dataloader'\n",
      "dataset_name = 'gf2'\n",
      "use_resume = False\n",
      "\n",
      "dict_keys(['entrypoint', 'pansharpening', 'BDPN', 'DCFNet', 'DiCNN', 'DRPNN', 'FusionNet', 'LAGNet', 'MSDCNN', 'PanNet', 'PNN', 'myFusionNet'])\n",
      "=> creating d:\\Python\\gitSync\\AEM\\results\\pansharpening\\wv3\\FusionNet\\Test\n",
      "=> creating tfb logs d:\\Python\\gitSync\\AEM\\results\\pansharpening\\logs\\wv3\\FusionNet\\Test_2023-06-10-01-49-39\n",
      "loading Dataset_Pro: D:/Datasets/pansharpening/PanCollection/training_data/train_wv3_9714.h5 with 1023.0, keys: <KeysViewHDF5 ['gt', 'lms', 'ms', 'pan']>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Anaconda3\\envs\\latest\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "d:\\python\\gitsync\\udl-vis\\udl_vis\\AutoDL\\trainer.py:120: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.\n",
      "  'please set `runner` in your config.', UserWarning)\n",
      "d:\\python\\gitsync\\udl_package\\pancollection\\pancollection\\common\\dataset.py:21: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  data = h5py.File(file_path)  # NxCxHxW = 0x1x2x3\n",
      "d:\\python\\gitsync\\udl-vis\\udl_vis\\mmcv\\runner\\checkpoint.py:585: UserWarning: checkpoint in directory d:\\Python\\gitSync\\AEM\\results\\pansharpening\\wv3\\FusionNet\\Test\\model_2023-06-10-01-49-39\\checkpoint don't exist or is empty\n",
      "  warnings.warn(msg)\n",
      "\u001b[37m- loading best model failed, maybe it's from scratch currently.\u001b[0m\n",
      "\u001b[37m- no checkpoint found at .pth.tar\u001b[0m\n",
      "\u001b[37m- resumed epoch 1, iter 1\u001b[0m\n",
      "\u001b[37m- Start running, host: msi@LAPTOP-JTEEC3T0, work_dir: d:\\Python\\gitSync\\AEM\\results\\pansharpening\\wv3\\FusionNet\\Test\\model_2023-06-10-01-49-39\u001b[0m\n",
      "\u001b[37m- Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(NORMAL      ) ModelCheckpoint                    \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) ModelCheckpoint                    \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) ModelCheckpoint                    \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \u001b[0m\n",
      "\u001b[37m- workflow: [('train', 1)], max: 400 epochs\u001b[0m\n",
      "\u001b[37m- Checkpoints will be saved to d:\\Python\\gitSync\\AEM\\results\\pansharpening\\wv3\\FusionNet\\Test\\model_2023-06-10-01-49-39\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9714, 1, 64, 64) (9714, 8, 64, 64) (9714, 8, 64, 64) (9714, 8, 16, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m- Epoch [1]/[400][50/303]\tlr: 2.000e-04, eta: 3:57:48, time: 0.118, data_time: 0.049, memory: 305MB, pan2ms: 0.00879, loss: 0.00879, grad_norm: 0.02547\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12620\\3829542408.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m                          ) # 'test_wv3_OrigScale_multiExm1.h5'\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTaskDispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_task\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetDataSession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\python\\gitsync\\udl-vis\\udl_vis\\AutoDL\\trainer.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(cfg, build_model, getDataSession)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[0mgetDataSession\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[0mdistributed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m         meta={})\n\u001b[0m",
      "\u001b[1;32md:\\python\\gitsync\\udl-vis\\udl_vis\\AutoDL\\trainer.py\u001b[0m in \u001b[0;36mtrainer\u001b[1;34m(cfg, logger, build_model, getDataSession, distributed, meta)\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;31m# 载入数据，运行模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[1;31m############################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m     \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkflow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\gitsync\\udl-vis\\udl_vis\\mmcv\\runner\\epoch_based_runner.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, data_loaders, workflow, max_epochs, **kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'train'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_epochs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m                     \u001b[0mepoch_runner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mearlyStop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m                 \u001b[0mprint_log\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model train has diverged, python will stop training\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\gitsync\\udl-vis\\udl_vis\\mmcv\\runner\\epoch_based_runner.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, data_loader, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'before_train_epoch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Prevent possible deadlock during epoch transition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'before_train_iter'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\Anaconda3\\envs\\latest\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    626\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 628\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\Anaconda3\\envs\\latest\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    672\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\Anaconda3\\envs\\latest\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Python\\Anaconda3\\envs\\latest\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Handle `CustomType` automatically\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \"\"\"\n\u001b[1;32m--> 265\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Python\\Anaconda3\\envs\\latest\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcollate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[1;31m# The mapping type may not support `__init__(iterable)`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\Anaconda3\\envs\\latest\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcollate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[1;31m# The mapping type may not support `__init__(iterable)`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\Anaconda3\\envs\\latest\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcollate_fn_map\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0melem_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcollate_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\Anaconda3\\envs\\latest\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pancollection import TaskDispatcher, trainer, build_model, getDataSession\n",
    "dataset_name = \"gf2\"\n",
    "arch = \"myFusionNet\"\n",
    "cfg = TaskDispatcher.new(task='pansharpening', mode='entrypoint', arch=arch,\n",
    "                         dataset_name=dataset_name, eval=False, use_resume=False,\n",
    "                        #  dataset={'test': f'test_{dataset_name}_multiExm1_hp.h5'}\n",
    "                        #  if arch == \"PanNet\" else {'test': f'test_{dataset_name}_multiExm1.h5'}\n",
    "                         ) # 'test_wv3_OrigScale_multiExm1.h5'\n",
    "print(TaskDispatcher._task.keys())\n",
    "trainer.main(cfg, build_model, getDataSession)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
